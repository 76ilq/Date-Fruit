# -*- coding: utf-8 -*-
"""KNN-modelipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vhRr8tAMoLd05vJMSO7FKm-Igg_WFCBg

First let's read the data
"""

import matplotlib.pyplot as plt
import numpy as np
import os
import tensorflow as tf
import cv2
import numpy as np
import pandas as pd
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import minmax_scale
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import tensorflow as tf

import kagglehub

# Download latest version
path = kagglehub.dataset_download("muratkokludataset/date-fruit-datasets")

print("Path to dataset files:", path)

# List files and folders
for root, dirs, files in os.walk(path):
    print(f"Root: {root}")
    print(f"Directories: {dirs}")
    print(f"Files: {files}\n")

data = pd.read_excel('/root/.cache/kagglehub/datasets/muratkokludataset/date-fruit-datasets/versions/1/Date_Fruit_Datasets/Date_Fruit_Datasets.xlsx')

print(data.head())

data

data.info()

data['Class'].unique()

X = data.drop(['Class'],axis=1)
y = data['Class']

X

y

"""Data Transformation"""

def transformation(X,y):
    X_scaler = minmax_scale(X)
    X = pd.DataFrame(X_scaler)

    class_encoder = LabelEncoder()
    y = class_encoder.fit_transform(y)
    return X,y

X,y = transformation(X,y)
print(X)
print(y)

"""Splitting the data train data,test data, validation data"""

np.unique(y)

def split_data(X,y,train_size,random_state):
    X_train,X_test,y_train,y_test = train_test_split(X, y, train_size = train_size, random_state=random_state)
    return X_train,X_test,y_train,y_test

X_train,X_temp,y_train,y_temp = split_data(X,y,0.8,42)
X_val,X_test,y_val,y_test = split_data(X_temp,y_temp,0.5,42)
print(f"Length of the dataset: {len(X)}")
print(f"Length of the training dataset: {len(X_train)}")
print(f"Length of the validation dataset: {len(X_val)}")
print(f"Length of the test dataset: {len(X_test)}")

print("Training set class distribution:")
print(pd.Series(y_train).value_counts())

print("Validation set class distribution:")
print(pd.Series(y_val).value_counts())

print("Test set class distribution:")
print(pd.Series(y_test).value_counts())

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, accuracy_score

knn_model = KNeighborsClassifier(n_neighbors=5)

knn_model.fit(X_train, y_train)

y_pred = knn_model.predict(X_test)
#['BERHI', 'DEGLET', 'DOKOL', 'IRAQI', 'ROTANA', 'SAFAVI', 'SOGAY']
target_names = ['BERHI', 'DEGLET', 'DOKOL', 'IRAQI', 'ROTANA', 'SAFAVI', 'SOGAY']
print(classification_report(y_test, y_pred,target_names=target_names))

accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, y_pred)

disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)
disp.plot(cmap=plt.cm.Blues)

plt.title("Confusion Matrix")
plt.show()

from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score


overall_precision = precision_score(y_test, y_pred, average='weighted')
overall_recall = recall_score(y_test, y_pred, average='weighted')
overall_f1_score = f1_score(y_test, y_pred, average='weighted')
overall_accuracy = accuracy_score(y_test, y_pred)

print("Overall Model Performance:")
print(f"Precision: {overall_precision:.2f}")
print(f"Recall: {overall_recall:.2f}")
print(f"F1-Score: {overall_f1_score:.2f}")
print(f"Accuracy: {overall_accuracy:.2f}")

import pandas as pd

# إنشاء DataFrame لعرض النتائج
results = pd.DataFrame({
    'Actual': y_test,
    'Predicted': y_pred
})

# إضافة عمود للتحقق من الصحة (صحيحة أم خاطئة)
results['Correct'] = results['Actual'] == results['Predicted']

# عرض النتائج+
print(results)

# حفظ النتائج في ملف CSV (اختياري)
results.to_csv("classification_results.csv", index=False)

train_accuracy = knn_model.score(X_train, y_train)


test_accuracy = knn_model.score(X_test, y_test)


print(f"Training Accuracy: {train_accuracy:.2f}")
print(f"Testing Accuracy: {test_accuracy:.2f}")


if train_accuracy > 0.9 and (train_accuracy - test_accuracy) > 0.1:
    print("The model might be overfitting.")
elif train_accuracy < 0.7 and test_accuracy < 0.7:
    print("The model might be underfitting.")
else:
    print("The model seems to be fitting well.")

import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
import pandas as pd


y_pred = knn_model.predict(X_test)

#
pca = PCA(n_components=2)
X_test_reduced = pca.fit_transform(X_test)


df_actual = pd.DataFrame(X_test_reduced, columns=['PCA1', 'PCA2'])
df_actual['Class'] = y_test

df_predicted = pd.DataFrame(X_test_reduced, columns=['PCA1', 'PCA2'])
df_predicted['Class'] = y_pred


plt.figure(figsize=(10, 8))
colors = ['red', 'blue', 'green', 'purple', 'orange', 'brown', 'pink']
for i, cls in enumerate(df_actual['Class'].unique()):
    subset = df_actual[df_actual['Class'] == cls]
    plt.scatter(subset['PCA1'], subset['PCA2'], label=f'Actual Class {cls}', color=colors[i], alpha=0.7, edgecolor='k')

plt.title('Actual Class Distribution (Test Data)', fontsize=16)
plt.xlabel('PCA1', fontsize=12)
plt.ylabel('PCA2', fontsize=12)
plt.legend()
plt.grid()
plt.show()


plt.figure(figsize=(10, 8))
for i, cls in enumerate(df_predicted['Class'].unique()):
    subset = df_predicted[df_predicted['Class'] == cls]
    plt.scatter(subset['PCA1'], subset['PCA2'], label=f'Predicted Class {cls}', color=colors[i], alpha=0.7, edgecolor='k')

plt.title('Predicted Class Distribution (Test Data)', fontsize=16)
plt.xlabel('PCA1', fontsize=12)
plt.ylabel('PCA2', fontsize=12)
plt.legend()
plt.grid()
plt.show()

misclassified = y_test != y_pred
df_misclassified = df_actual[misclassified]

plt.figure(figsize=(10, 8))
for i, cls in enumerate(df_actual['Class'].unique()):
    subset = df_actual[df_actual['Class'] == cls]
    plt.scatter(subset['PCA1'], subset['PCA2'], label=f'Actual Class {cls}', alpha=0.7)
plt.scatter(df_misclassified['PCA1'], df_misclassified['PCA2'], color='black', label='Misclassified', marker='x')
plt.title('Misclassified Points')
plt.xlabel('PCA1')
plt.ylabel('PCA2')
plt.legend()
plt.grid()
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# محاكاة أداء التدريب والاختبار (مثال إذا لم تكن لديك بيانات لكل جولة)
epochs = np.arange(1, 11)  # نفترض 10 جولات
train_accuracy = [0.75, 0.78, 0.81, 0.84, 0.87, 0.89, 0.91, 0.92, 0.93, 0.93]
test_accuracy = [0.72, 0.75, 0.79, 0.82, 0.85, 0.88, 0.90, 0.91, 0.91, 0.91]

# الرسم
plt.figure(figsize=(10, 6))
plt.plot(epochs, train_accuracy, label='Training Accuracy', marker='o', linestyle='-', color='blue')
plt.plot(epochs, test_accuracy, label='Testing Accuracy', marker='o', linestyle='--', color='green')

# إضافة التفاصيل
plt.title('Training vs Testing Accuracy', fontsize=16)
plt.xlabel('Iterations', fontsize=12)
plt.ylabel('Accuracy', fontsize=12)
plt.ylim(0, 1.1)  # لتحديد المدى من 0 إلى 1.1
plt.xticks(epochs)
plt.legend()
plt.grid(alpha=0.5, linestyle='--')
plt.show()